{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from math import sqrt, pi\n",
    "\n",
    "import ijson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import plotly.express as px\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from kcmc_instance import KCMC_Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCE Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PREFIX = '/data/dynamodb_objs'\n",
    "\n",
    "# LISTING FILES\n",
    "files_list = sorted([f for f in os.listdir(INPUT_PREFIX) if f.endswith('.json')])\n",
    "len(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class open_and_replace(object):\n",
    "    \n",
    "    def __init__(self, filepath, readmode='r', to_replace=None):\n",
    "        if to_replace is None: to_replace = {}\n",
    "        self.to_replace = {str(key): str(value)\n",
    "                           for key, value in to_replace.items()}\n",
    "        self.filepath = filepath\n",
    "        self.readmode = readmode\n",
    "        \n",
    "    def replace_inline(self, data):\n",
    "        for key, value in self.to_replace.items():\n",
    "            data = data.replace(key, value)\n",
    "        return data\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.fileobj = open(self.filepath, self.readmode)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        self.fileobj.close()\n",
    "    \n",
    "    def read(self, *args, **kwargs):\n",
    "        data = self.fileobj.read(*args, **kwargs)\n",
    "        return self.replace_inline(data)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for data in self.fileobj:\n",
    "            yield self.replace_inline(data)\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        raise NotImplementedError(f'CLASS <open_and_replace> DOES NOT HAVE METHOD <{attr}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fix = {\n",
    "    \": Infinity, \": ': \"Infinity\", ',\n",
    "    ''',\"'p42''': ''','p42''',\n",
    "    ''',\"'p94''': ''','p94''',\n",
    "    ': nuln, ': ':null, ',\n",
    "    '\": 0.0. ': '\": 0.0, ',\n",
    "    ''',\"'1')\": ''': ''','1')\": ''',\n",
    "    ''',\"'i364',''': ''','i364',''',\n",
    "    '''\"\"('i228', ''': '''\"('i228', ''',\n",
    "    ''',\"'i168',''': ''','i168','''\n",
    "}\n",
    "\n",
    "def _parse_file(file):\n",
    "    \n",
    "    # RESULTS BUFFER\n",
    "    result = {'variables': {'y': 'trimmed out', 'x': {}},\n",
    "              'time': {'wall': None, 'setup': {'model': None}},\n",
    "              'file': file, 'gurobi_logs': ''}\n",
    "    \n",
    "    # MAIN PARSING\n",
    "    with open_and_replace(\n",
    "        INPUT_PREFIX+\"/\"+file,\n",
    "        to_replace=json_fix\n",
    "    ) as f:  \n",
    "        for prefix, event, value in ijson.parse(f):\n",
    "\n",
    "            # IGNORED\n",
    "            if prefix in {\n",
    "                None, '', ' ', 'variables',\n",
    "                'K', 'M', 'kcmc_k', 'kcmc_m',\n",
    "                'serial', 'seed', 'time_limit', 'queued',\n",
    "                'results_single_flow', 'results_multi_flow'\n",
    "            }: continue\n",
    "\n",
    "            # IGNORE FOR NOW THE GUROBI LOGS\n",
    "            elif prefix == 'gurobi_logs': continue\n",
    "            elif prefix == 'gurobi_logs.item':\n",
    "                if isinstance(value, list):\n",
    "                    for i in value: result['gurobi_logs'] += i\n",
    "                elif value is None: continue\n",
    "                else: result['gurobi_logs'] += value\n",
    "\n",
    "            # PARSING OF GUROBI DEFAULT RESULT FORMAT\n",
    "            elif prefix == 'json_solution':\n",
    "                result.update(json.loads(value))\n",
    "\n",
    "            # PARSING OF VARIABLE Y\n",
    "            elif prefix.startswith('variables.y'): continue\n",
    "\n",
    "            # PARSING OF VARIABLE X\n",
    "            elif prefix.startswith('variables.x'):\n",
    "                if prefix == 'variables.x': continue\n",
    "                key = prefix[len('variables.x.'):]\n",
    "                if ', ' in key:\n",
    "                    item, tree = key.split(\"', '\")\n",
    "                    item = int(item.split('i')[1])\n",
    "                    tree = int(tree.split(\"'\")[0])\n",
    "                else:\n",
    "                    tree = 0\n",
    "                    item = int(key.split('i')[1])            \n",
    "                if tree not in result['variables']['x']: result['variables']['x'][tree] = {}\n",
    "                result['variables']['x'][tree][item] = 0 if value is None else int(abs(value))\n",
    "\n",
    "            # IGNORE FOR NOW THE PARSING OF DETAILED RUNTIMES\n",
    "            elif prefix.startswith('time'): continue\n",
    "\n",
    "            # PARSING OF SIMPLE COPY DATA\n",
    "            elif prefix == 'threads': result['threads'] = value\n",
    "            elif prefix == 'gurobi_model_fingerprint': result['gurobi_model_fingerprint'] = value\n",
    "\n",
    "            elif prefix == 'gurobi_runtime': result['gurobi_runtime'] = float(value)\n",
    "            elif prefix == 'simplex_iterations_count': result['simplex_iterations_count'] = float(value)\n",
    "            elif prefix == 'binary_variables': result['binary_variables'] = value\n",
    "            elif prefix == 'solutions_count': result['solutions_count'] = value\n",
    "            elif prefix == 'node_count': result['node_count'] = value\n",
    "            elif prefix == 'status_code': result['status_code'] = value\n",
    "            elif prefix == 'status': result['status'] = value\n",
    "            elif prefix == 'mip_gap': result['mip_gap'] = value\n",
    "\n",
    "            elif prefix == 'K': result['K'] = value\n",
    "            elif prefix == 'M': result['M'] = value\n",
    "            elif prefix == 'gurobi_model_type': result['gurobi_model_type'] = value\n",
    "            elif prefix == 'instance_key': result['instance_key'] = value\n",
    "            elif prefix == 'coverage_density': result['coverage_density'] = float(value)\n",
    "            elif prefix == 'communication_density': result['communication_density'] = float(value)\n",
    "\n",
    "            # UNMAPPED KEY ERROR\n",
    "            else: raise NotImplementedError(' | '.join(map(str, [file, prefix, event, value])))\n",
    "\n",
    "    # CLOSEUP OF THE X VARIABLE\n",
    "    result['variables']['x'] = {\n",
    "        tree: np.packbits([bool(item[pos]) for pos in sorted(item.keys())]).tolist()\n",
    "            for tree, item in result['variables']['x'].items()\n",
    "    }\n",
    "    \n",
    "    # CLOSEUP OF THE GUROBI LOGS\n",
    "    result['gurobi_logs'] = None if len(result['gurobi_logs']) == 0 \\\n",
    "                                 else result['gurobi_logs'].strip()\n",
    "\n",
    "    # DETAILED TIMING\n",
    "    with open_and_replace(\n",
    "        INPUT_PREFIX+\"/\"+file,\n",
    "        to_replace=json_fix\n",
    "    ) as f:\n",
    "        for key, value in ijson.kvitems(f, 'time'):\n",
    "            if key == 'wall':\n",
    "                result['time']['wall'] = value[1]-value[0]\n",
    "                continue\n",
    "            # Key must be \"setup\"\n",
    "            for skey, svalue in value.items():\n",
    "                if skey == 'model':\n",
    "                    result['time']['setup']['model'] = svalue[1]-svalue[0]\n",
    "                else:\n",
    "                    result['time']['setup'][skey] = {\n",
    "                        sskey: ssvalue[1]-ssvalue[0]\n",
    "                        for sskey, ssvalue in svalue.items()\n",
    "                    }\n",
    "    \n",
    "    # RETURNS            \n",
    "    return result\n",
    "\n",
    "def parse_file(file):\n",
    "    try:\n",
    "        return _parse_file(file)\n",
    "    except Exception as exp:\n",
    "        print(file, str(exp))\n",
    "        raise exp\n",
    "        #return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(files_list) > 0:\n",
    "    pool = multiprocessing.Pool()\n",
    "\n",
    "    CHUNKSIZE = 100\n",
    "    def chunks(lst, n): return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "\n",
    "    for chunknum, files_chunk in enumerate(chunks(files_list, CHUNKSIZE)):\n",
    "        filename = f'/data/parsed_results/{chunknum}.pq'\n",
    "        if os.path.exists(filename):\n",
    "            print(chunknum, filename)\n",
    "            # Comment the line below to overwrite existing parsed results\n",
    "            continue\n",
    "        df = []\n",
    "        for file in tqdm(pool.imap_unordered(parse_file, files_chunk),\n",
    "                         total=len(files_chunk)):\n",
    "            if file is None: continue\n",
    "            df.append(file.copy())\n",
    "\n",
    "        # Format the DataFrame\n",
    "        df = pd.DataFrame(df).sort_values('instance_key').reset_index(drop=True).copy()\n",
    "        df = df.apply(lambda col: col.fillna('').astype(str)).copy()\n",
    "        df.to_parquet(filename)\n",
    "        print(chunknum, filename, len(df))\n",
    "\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = pd.read_csv('results/preprocessor/optimizer_dinic.csv', header=None, sep='\\t')\n",
    "prep.columns = ['instance_key', 'K', 'M',\n",
    "                'prep_heuristic', 'prep_runtime_us', 'prep_valid',\n",
    "                'prep_size', 'prep_compression_rate', 'prep_result']\n",
    "\n",
    "int_cols = ['K', 'M', 'prep_runtime_us', 'prep_size']\n",
    "prep.loc[:, int_cols] = prep[int_cols].apply(lambda col: col.astype(int))\n",
    "prep.loc[:, 'prep_compression_rate'] = prep['prep_compression_rate'].astype(float)\n",
    "prep.loc[:, 'instance_key'] = 'KCMC_'+prep['instance_key'].str.replace(' ', '_').str.replace(';', '_')\n",
    "prep.loc[:, 'prep_runtime'] = prep['prep_runtime_us'] / 1_000_000\n",
    "prep.loc[:, 'prep_valid'] = prep['prep_valid'] == 'OK'\n",
    "\n",
    "prep.to_parquet('/data/preprocessing.parquet')\n",
    "\n",
    "len(prep), prep.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.loc[:, 'pois'] = prep['instance_key'].str.split('_').str[1]\n",
    "prep.loc[:, 'sensors'] = prep['instance_key'].str.split('_').str[2]\n",
    "\n",
    "(prep\n",
    "    [prep['prep_heuristic'].str.startswith('ff_dinic')]\n",
    "    [['pois', 'sensors', 'K', 'M',\n",
    "      # 'prep_heuristic',\n",
    "      'prep_runtime', 'prep_valid', 'prep_size']]\n",
    "    .groupby(['pois', 'sensors', 'K', 'M'])\n",
    "    .mean()\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values(['pois', 'sensors', 'K', 'M'])\n",
    ")[['pois', 'sensors', 'K', 'M',\n",
    "   'prep_valid',\n",
    "   'prep_size',\n",
    "   'prep_runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
